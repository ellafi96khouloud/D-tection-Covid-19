# -*- coding: utf-8 -*-
"""PFE2021.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1maRbtattdXG8PEmBLR2OKoHgC6jGYT7d
"""

!pip install tensorflow-gpu

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
from pathlib import Path
import os.path
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.layers import Input, Lambda, Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img
from tensorflow.keras.models import Sequential
import numpy as np
import cv2
import tensorflow as tf
from glob import glob
import matplotlib.pyplot as plt

# Create a list with the filepaths for training and testing
IMAGE_SIZE = [224, 224]
dir_ = Path('/content/drive/MyDrive/PFE2021/Test')
train_file_paths = list(dir_.glob(r'**/*.png'))

dir_ = Path('/content/drive/MyDrive/PFE2021/Train')
test_file_paths = list(dir_.glob(r'**/*.png'))

def proc_img(filepath):
    """ Create a DataFrame with the filepath and the labels of the pictures
    """

    labels = [str(filepath[i]).split("/")[-2] \
              for i in range(len(filepath))]

    filepath = pd.Series(filepath, name='Filepath').astype(str)
    labels = pd.Series(labels, name='Label')

    # Concatenate filepaths and labels
    df = pd.concat([filepath, labels], axis=1)

    # Shuffle the DataFrame and reset index
    df = df.sample(frac=1,random_state=0).reset_index(drop = True)
    
    return df

train_df = proc_img(train_file_paths)
test_df = proc_img(test_file_paths)

print(f'Number of pictures in the training set: {train_df.shape[0]}')
print(f'Number of pictures in the test set: {test_df.shape[0]}')



print(f'Number of different labels: {len(train_df.Label.unique())}\n')
print(f'Labels: {train_df.Label.unique()}')

# The DataFrame with the filepaths in one column and the labels in the other one
train_df.head(10)

# Display the number of pictures of each category in the training set
import seaborn as sns
vc = train_df['Label'].value_counts()
plt.figure(figsize=(20,5))
sns.barplot(x = sorted(vc.index), y = vc, palette = "rocket")
plt.title("Number of pictures of each category in the training set", fontsize = 15)
plt.show()

# Display some pictures of the dataset
fig, axes = plt.subplots(nrows=4, ncols=6, figsize=(15, 7),
                        subplot_kw={'xticks': [], 'yticks': []})

for i, ax in enumerate(axes.flat):
    ax.imshow(plt.imread(train_df.Filepath[i]))
    ax.set_title(train_df.Label[i], fontsize = 15)
plt.tight_layout(pad=0.5)
plt.show()

vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)

vgg.summary()

for layer in vgg.layers:
    layer.trainable = False

folders = glob('/content/drive/MyDrive/KHOULOUD/Train/*')

folders

x = Flatten()(vgg.output)

prediction = Dense(len(folders), activation='softmax')(x)

model = Model(inputs = vgg.input, outputs = prediction)

model.summary()

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)
test_datagen = ImageDataGenerator(rescale = 1./255)

training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/PFE2021/Train', target_size = (224, 224),
                                                 batch_size = 32, class_mode = 'categorical')

test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/PFE2021/Test', target_size = (224, 224),
                                            batch_size = 32, class_mode = 'categorical')

vgg_model = model.fit_generator(training_set, validation_data = test_set, epochs = 10, steps_per_epoch = len(training_set),
  validation_steps = len(test_set))

vgg_model.history

# plot the loss
plt.plot(vgg_model.history['loss'], label='train loss')
plt.plot(vgg_model.history['val_loss'], label='val loss')
plt.legend()
plt.show()
plt.savefig('LossVal_loss')

# plot the accuracy
plt.plot(vgg_model.history['accuracy'], label='train acc')
plt.plot(vgg_model.history['val_accuracy'], label='val acc')
plt.legend()
plt.show()
plt.savefig('AccVal_acc')

from tensorflow.keras.models import load_model
model.save('vgg_PFE2021.h5')

y_pred = model.predict(test_set)
y_pred

import numpy as np
y_pred = np.argmax(y_pred, axis=1)
y_pred

plt.imshow(plt.imread("/content/drive/MyDrive/PFE2021/Test/Viral Pneumonia/Viral Pneumonia-101.png"))
plt.title('Viral Pneumonia')

plt.imshow(plt.imread("/content/drive/MyDrive/PFE2021/Test/COVID/COVID-10.png"))
plt.title('COVID-19')

plt.imshow(plt.imread("/content/drive/MyDrive/PFE2021/Test/Lung_Opacity/Lung_Opacity-4824.png"))
plt.title('Lung_Opacity')

plt.imshow(plt.imread("/content/drive/MyDrive/PFE2021/Test/Normal/Normal-100.png"))
plt.title('Normal')

vgg_load = load_model('vgg_PFE2021.h5')

def prepare(filepath):
    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR) # Reading the file
    img_array = img_array / 255
    new_array = cv2.resize(img_array, (224, 224)) # resizing the img_array to (224,224)
    return new_array.reshape(-1, 224, 224, 3) # reshaping the new data

model = tf.keras.models.load_model("vgg_PFE2021.h5")

prediction = model.predict([prepare("/content/drive/MyDrive/PFE2021/Train/COVID/COVID-1000.png")])
np.argmax(prediction)

class_dict = training_set.class_indices
class_dict

if np.argmax(prediction) == 0:
    print("COVID-19")
elif np.argmax(prediction) == 1:
    print("Lung_Opacity")
elif np.argmax(prediction) == 2:
    print("TNormal")
else:
    print("Viral Pneumonia")